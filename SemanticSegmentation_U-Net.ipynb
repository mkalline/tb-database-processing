{"cells":[{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"CFollV5hsLEd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4YjzS7sw0SwG"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization, ReLU, Conv2DTranspose, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Permute, multiply, Activation\n","from tensorflow.keras import Model\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from skimage.io import imread, imshow\n","from skimage.transform import resize\n","from skimage.measure import regionprops, label\n","from skimage.color import rgb2hsv, rgb2gray\n","import cv2"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"PGrmyckQ1Nvx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6GuV2f-THuRD"},"source":["## Preparing the Data\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cRvNrFvjUdlj"},"outputs":[],"source":["batch_size = 10\n","img_height = 400\n","img_width = 400\n","rescale = 1./255\n","data_dir = '/DDS3/'\n","\n","\n","def preprocessor_mask(image):\n","   image = (255-image)\n","   image = image[:,:,0]\n","   image = np.reshape(image, (img_width, img_height, 1))\n","   return image\n","\n","def preprocessor_weight(image):\n","   image = (255-image)\n","   image = image/255\n","   class_weights = tf.constant([1.0406, 50.2519])\n","   class_weights = class_weights/tf.reduce_sum(class_weights)\n","   sample_weights = tf.gather(class_weights, indices=tf.cast(image, tf.int32))\n","   return np.asarray(sample_weights)\n","\n","seed = 909\n","image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=rescale)\n","mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=rescale,\n","                                                               preprocessing_function=preprocessor_mask)\n","weight_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessor_weight)\n","\n","image_generator_train =image_datagen.flow_from_directory(data_dir + 'TRAINING SET/IMAGE',\n","                                                    class_mode=None,\n","                                                    batch_size = batch_size,\n","                                                    target_size = (img_width, img_height),\n","                                                    seed = seed,\n","                                                    shuffle=False)\n","mask_generator_train = mask_datagen.flow_from_directory(data_dir + 'TRAINING SET/MASK',\n","                                                   class_mode=None,\n","                                                   batch_size = batch_size,\n","                                                   color_mode = 'grayscale',\n","                                                   target_size = (img_width, img_height),\n","                                                   seed = seed,\n","                                                   shuffle=False)\n","\n","weight_generator_train = weight_datagen.flow_from_directory(data_dir + 'TRAINING SET/MASK',\n","                                                   class_mode=None,\n","                                                   batch_size = batch_size,\n","                                                   color_mode = 'grayscale',\n","                                                   target_size = (img_width, img_height),\n","                                                   seed = seed,\n","                                                   shuffle=False)\n","\n","train_generator = zip(image_generator_train, mask_generator_train, weight_generator_train)\n","\n","image_generator_valid =image_datagen.flow_from_directory(data_dir + 'VALIDATION SET/IMAGE',\n","                                                   class_mode=None,\n","                                                   batch_size = batch_size,\n","                                                   target_size = (img_width, img_height),\n","                                                   seed = seed,\n","                                                   shuffle=False)\n","mask_generator_valid = mask_datagen.flow_from_directory(data_dir + 'VALIDATION SET/MASK',\n","                                                   class_mode=None,\n","                                                   batch_size = batch_size,\n","                                                   target_size = (img_width, img_height),\n","                                                   seed = seed,\n","                                                   color_mode = 'grayscale',\n","                                                   shuffle=False)\n","valid_generator = zip(image_generator_valid, mask_generator_valid)"]},{"cell_type":"markdown","metadata":{"id":"SM0aKH9ETg8U"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JUOpvgl8zS8v"},"outputs":[],"source":["num_classes = 2\n","\n","inputs = tf.keras.layers.Input((400, 400, 3))\n","\n","c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n","c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n","p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n","\n","c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n","c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n","p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n","\n","c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n","c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n","p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n","\n","c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n","c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n","p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n","\n","c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n","c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n","\n","u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n","u6 = tf.keras.layers.concatenate([u6, c4])\n","u6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n","u6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n","\n","\n","u7 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(u6)\n","u7 = tf.keras.layers.concatenate([u7, c3])\n","u7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n","u7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n","\n","\n","u8 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(u7)\n","u8 = tf.keras.layers.concatenate([u8, c2])\n","u8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n","u8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n","\n","u9 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(u8)\n","u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n","u9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n","u9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n","\n","\n","outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='softmax')(u9)\n","model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NdOfEPKEpzV3"},"outputs":[],"source":["model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n","                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","                metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rsc4mxwwpxfR"},"outputs":[],"source":["STEP_SIZE_TRAIN=6000//batch_size\n","STEP_SIZE_VALID=1000//batch_size\n","\n","model.fit(train_generator,\n","          steps_per_epoch=STEP_SIZE_TRAIN,\n","          validation_data=valid_generator,\n","          validation_steps=STEP_SIZE_VALID,\n","          epochs=30)"]},{"cell_type":"markdown","metadata":{"id":"tJqjTkcfGrAL"},"source":["#### Save the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IhDkY43rfNrE"},"outputs":[],"source":["model.save('model_segmentation_UNet.h5')"]},{"cell_type":"markdown","metadata":{"id":"U6JpCZKqPKrR"},"source":["##Evaluating"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aa8uRyj14p1u"},"outputs":[],"source":["def loadImages(path, subfolder):\n","    '''Put files into lists and return them as one list with all images\n","     in the folder'''\n","    image_files = sorted([os.path.join(path, subfolder, file)\n","                          for file in os.listdir(path + \"/\" + subfolder)\n","                          if file.endswith('.bmp')])\n","\n","    return image_files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LjA6mD10Eatj"},"outputs":[],"source":["def create_mask(pred_mask):\n","  pred_mask = tf.argmax(pred_mask, axis=-1)\n","  pred_mask = pred_mask[..., tf.newaxis]\n","  return pred_mask\n","\n","def segmentation_images(img_mosaico):\n","    image = img_mosaico/255\n","    m, n, c = image.shape\n","    image = np.reshape(image, (1, m, n, c))\n","    pred_mask = model(image, training=False)\n","    Y_new = np.asarray(create_mask(pred_mask[0]), dtype='uint8')\n","    Y_new = cv2.resize(Y_new, dsize=(400, 400), interpolation=cv2.INTER_CUBIC)\n","    Y_new = np.reshape(Y_new, (400, 400, 1))\n","\n","    return Y_new"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4s-Pme9Hltbq"},"outputs":[],"source":["def display(display_list):\n","  plt.figure(figsize=(15, 15))\n","  title = [\"Input Image\", \"True Mask\", \"Predicted Mask\"]\n","  for i in range(len(display_list)):\n","    plt.subplot(1, len(display_list), i+1)\n","    plt.title(title[i])\n","    plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n","    plt.axis(\"off\")\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YWvk_KWqIK26"},"outputs":[],"source":["def verify_metrics(images_conj, images_mask_conj):\n","    VP = 0\n","    FP = 0\n","    VN = 0\n","    FN = 0\n","\n","    for i in range(len(images_conj)):\n","        img_rgb_ori = imread(images_conj[i])\n","        img_pred = segmentation_images(img_rgb_ori)\n","        img_mask = imread(images_mask_conj[i])\n","        img_mask = np.reshape(img_mask, (400, 400, 1))\n","        img_mask = (255-img_mask)\n","        display([img_rgb_ori, img_mask, img_pred])\n","\n","        for c in range(0,10):\n","          for l in range(0,10):\n","            part_img_mask = img_mask[l*40:40+l*40,c*40:40+c*40]\n","            part_img_pred = img_pred[l*40:40+l*40,c*40:40+c*40]\n","            part_img_orig = img_rgb_ori[l*40:40+l*40,c*40:40+c*40,:]\n","\n","            label_pred, n_pred = label(part_img_pred, connectivity=2, return_num=True)\n","            regions_pred = regionprops(label_pred)\n","\n","            label_mask, n_orig = label(part_img_mask, connectivity=2, return_num=True)\n","            regions_mask = regionprops(label_mask)\n","\n","            n_pred = 0\n","            for props_pred in regions_pred:\n","              if (props_pred.area > 25) and props_pred.area < 900):\n","                n_pred = n_pred +1\n","\n","            if (n_orig == 1 and n_pred == 1):\n","                VP = VP + n_pred\n","            elif (n_orig == 1 and n_pred > 1):\n","                VP = VP + 1\n","                FP = FP + (n_pred - 1);\n","            elif (n_orig == 1 and n_pred == 0):\n","                FN = FN + n_orig\n","            elif (n_orig == 0 and n_pred != 0):\n","                FP = FP + n_pred\n","            elif (n_orig == 0 and n_pred == 0):\n","                VN = VN + 1\n","\n","    print(\"VP: \" + str(VP))\n","    print(\"FP: \" + str(FP))\n","    print(\"VN: \" + str(VN))\n","    print(\"FN: \" + str(FN))\n","\n","    Sensibilidade = VP/(VP+FN)\n","    Especificidade = VN/(VN+FP)\n","    Precisao = VP/(VP+FP)\n","    F1score = 2*((Precisao*Sensibilidade)/(Precisao+Sensibilidade))\n","    Acuracia = (VP+VN)/(VP+FN+FP+VN)\n","\n","    print(\" Accuracy: \" + str(Acuracia))\n","    print(\" Precision: \" + str(Precisao))\n","    print(\" Sensitivity: \" + str(Sensibilidade))\n","    print(\" Specifity: \" + str(Especificidade))\n","    print(\" F1score: \" + str(F1score))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UWyLOPHvYS4-"},"outputs":[],"source":["path_test = 'TESTING SET'\n","images_conj_test_path = 'IMAGE'\n","images_conj_test_mask_path = 'MASK'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AUK8Zca7Y_cd"},"outputs":[],"source":["images_conj_test = loadImages(path_test, images_conj_test_path)\n","images_conj_test_mask = loadImages(path_test, images_conj_test_mask_path)"]},{"cell_type":"code","source":["verify_metrics(images_conj_test, images_conj_test_mask)"],"metadata":{"id":"cHe3IATNgqs6"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["C6WtAUdbyLcc","QqCUu8I6yRxz","iIMRUklIzsKC","6GuV2f-THuRD","SM0aKH9ETg8U","xwO84GvPDpf7","Jfj3u7xZUcB-","y8WKHbssDtfr","egNcNyofwNuv","JWZih1swIPqX","5Sg4cCRufp0K","xltdrr3Xpfjv","tJqjTkcfGrAL","U6JpCZKqPKrR"],"provenance":[{"file_id":"1Q0baULAvka2UtIslHsqkQj4BIBoL88as","timestamp":1708703865706},{"file_id":"1IeOQJrclCXSAQcVh846-2fFPP-WxZ4ua","timestamp":1691175698794},{"file_id":"1wL9KP6QJXwImQMjVd5PJRj8A6-sGIpft","timestamp":1678807256274},{"file_id":"1RzO_u7r74t2zk6KU3zLWafWlccNqvWYq","timestamp":1616101805636},{"file_id":"10fG3m-Z5t_rV4YiybjxY1s7xvSG8jjIm","timestamp":1616096621403},{"file_id":"1k1jInV4H0ppsgyYlKTg3mm7HTlp_2Aix","timestamp":1595440393069},{"file_id":"1FNbXu-A0uqhLkCxlXj17M5ssELLH05ab","timestamp":1595423635260},{"file_id":"1p31RXvFUV885H0XhBNxyN3g7ZT5TtZUT","timestamp":1595089010499},{"file_id":"1q1dhwUiINe43iNVgg6ibJmGe9anpJVhg","timestamp":1594299265481},{"file_id":"1SLxBsI8UBCaUgBiBGmJ-3aDxhbC21Na-","timestamp":1594064213803}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}